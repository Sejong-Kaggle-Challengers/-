{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-02T09:44:41.236119Z","iopub.execute_input":"2021-10-02T09:44:41.237222Z","iopub.status.idle":"2021-10-02T09:44:41.241768Z","shell.execute_reply.started":"2021-10-02T09:44:41.237172Z","shell.execute_reply":"2021-10-02T09:44:41.240759Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('../input/titanic/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-02T09:44:41.244005Z","iopub.execute_input":"2021-10-02T09:44:41.244541Z","iopub.status.idle":"2021-10-02T09:44:41.263799Z","shell.execute_reply.started":"2021-10-02T09:44:41.244494Z","shell.execute_reply":"2021-10-02T09:44:41.262417Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"## sns.catplot 사용법\n## category를 나눠서 시각화하고 싶을 때 data,x,y,kind를 정해줄것.\nsns.catplot(data=data,x='Embarked',y='Survived',kind='bar')\n\n## Survived가 0,1로 되어있어있다.\n## bar에 세로줄은 S인 것들에 0,1의 추정치와 불확실성을 보여준다.","metadata":{"execution":{"iopub.status.busy":"2021-10-02T09:44:41.266047Z","iopub.execute_input":"2021-10-02T09:44:41.266335Z","iopub.status.idle":"2021-10-02T09:44:41.584276Z","shell.execute_reply.started":"2021-10-02T09:44:41.266307Z","shell.execute_reply":"2021-10-02T09:44:41.583239Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"g=sns.FacetGrid(data=data,col='Survived',row='Embarked')\n## 똑같이 data,col,row 이런식으로 주고 현재 가로는 Survived,세로는 Embarked\ng.map(sns.scatterplot,'Age','Fare','Sex')\ng.add_legend()\n## mapping 한다. sns.scatterplot을\n## scatterplot은 x='Age',y='Fare',hue='Sex' 이 순서는 인자를 주지않고 sns.scatterplot순서대로\n\n## 처음 간단하게만 볼때만 사용.","metadata":{"execution":{"iopub.status.busy":"2021-10-02T09:44:41.585646Z","iopub.execute_input":"2021-10-02T09:44:41.585883Z","iopub.status.idle":"2021-10-02T09:44:43.362259Z","shell.execute_reply.started":"2021-10-02T09:44:41.585857Z","shell.execute_reply":"2021-10-02T09:44:43.361349Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"## 1. countplot \n## 특정 조건에 만족하는 행들의 수를 보여주는\n## 데이터 균형 정도를 확인하는데 쓰면 좋을 것 같다. \n## data와 x만 필요하다. \n\n## 2. point,bar plot\n## 위에서 보여준 차트로, estimate 추정할 때 사용.\n## 보통 예측값이 카테고리 일 때 사용하면 좋을 것 같다.","metadata":{"execution":{"iopub.status.busy":"2021-10-02T09:44:43.364505Z","iopub.execute_input":"2021-10-02T09:44:43.364893Z","iopub.status.idle":"2021-10-02T09:44:43.369680Z","shell.execute_reply.started":"2021-10-02T09:44:43.364857Z","shell.execute_reply":"2021-10-02T09:44:43.368649Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"## seaborn 특징.\n## data : dataframe.\n## x,y : 가로,세로에 변수 이름을 문자열로 넣는다.\n## hue : hue가 있다면 hue는 data로 나눠주는 것이다. (안에서 나누기)\n## col : col이 있다면 col은 figure로 나눠주는 것이다. (밖에서 나누기)\n\n## 좀 꼬아져있는데 sns.boxplot은 ax가 가능하고, sns.catplot은 ax가 안된다. \n## facetgrid 때문인것 같다. \n\n## facetgrid\n## matplotlib의 subplots 느낌. figure를 나눠주는 느낌.\n## 그래서 catplot은 facetgrid를 return한다.\n## 즉, g=sns.catplot(..) 후에 g.set_xlabels(..)로 덧붙인다.","metadata":{"execution":{"iopub.status.busy":"2021-10-02T09:44:43.371103Z","iopub.execute_input":"2021-10-02T09:44:43.371439Z","iopub.status.idle":"2021-10-02T09:44:43.380039Z","shell.execute_reply.started":"2021-10-02T09:44:43.371389Z","shell.execute_reply":"2021-10-02T09:44:43.379255Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"## 이상치 제거 방법.\n## 꽤 좋은 방법인것 같다. \n\ndef detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)        \n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers  ","metadata":{"execution":{"iopub.status.busy":"2021-10-02T09:44:43.381230Z","iopub.execute_input":"2021-10-02T09:44:43.381459Z","iopub.status.idle":"2021-10-02T09:44:43.392248Z","shell.execute_reply.started":"2021-10-02T09:44:43.381434Z","shell.execute_reply":"2021-10-02T09:44:43.391243Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"## 데이터 합치기 \n## 합치는 것은 모든 데이터 안에서 스케일을 맞추기 위해서인데\n## data leakage - https://www.kaggle.com/c/titanic/discussion/174969 사실 합치는건 좋은게 아니라고한다. ","metadata":{"execution":{"iopub.status.busy":"2021-10-02T09:44:43.393676Z","iopub.execute_input":"2021-10-02T09:44:43.394112Z","iopub.status.idle":"2021-10-02T09:44:43.405689Z","shell.execute_reply.started":"2021-10-02T09:44:43.394083Z","shell.execute_reply":"2021-10-02T09:44:43.405102Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"## 결측값 처리 방법\n\n## 특정 열의 결측값들인 행들을 가져와서\n\nprint(data['Age'].isna().sum())\n\nindex_NaN_age = list(data[\"Age\"][data[\"Age\"].isnull()].index)\n\n## loop를 돌며 결측값이라면 주변 열의 데이터와 비슷한 데이터들만 모아서 중앙값으로 채운다.\n## 다만 그런 데이터 프레임이 없을 때 단순히 전체 데이터의 중앙값으로 채운다. \n\nfor i in index_NaN_age :\n    age_med = data[\"Age\"].median()\n    age_pred = data[\"Age\"][((data['SibSp'] == data.iloc[i][\"SibSp\"]) & (data['Parch'] == data.iloc[i][\"Parch\"]) & (data['Pclass'] == data.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(age_pred) : # 결측값을 확인할 때.\n        data['Age'].iloc[i] = age_pred\n    else :\n        data['Age'].iloc[i] = age_med\n        \nprint(data['Age'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2021-10-02T09:44:43.407079Z","iopub.execute_input":"2021-10-02T09:44:43.407824Z","iopub.status.idle":"2021-10-02T09:44:43.715891Z","shell.execute_reply.started":"2021-10-02T09:44:43.407790Z","shell.execute_reply":"2021-10-02T09:44:43.715069Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"## 모델링\n\n## 행들이 독립적이기 때문에 kfold로 baseline에 교차검증까지 돌려서 단순 점수 확인.\n## 점수 좋은 것들 중 best 모델 골라서 parameter tuning.\n## tuning은 gridsearch.\n## tuning 방법 중 bayesian optimization도 있고, optuna도 있다. \n\n## bayesian optimization\n## https://www.kaggle.com/vincentlugat/ieee-lgb-bayesian-opt\n## 함수를 불러와서 객체로 저장한다. \n## 후에 bound를 정하고 maximize를 한 후, 저장된 객체안에서 뽑아서 사용한다. \n\n## optuna\n## https://www.kaggle.com/akmeghdad/tps-0921-essential\n## bayesian과 같다. ","metadata":{"execution":{"iopub.status.busy":"2021-10-02T09:44:43.717072Z","iopub.execute_input":"2021-10-02T09:44:43.717299Z","iopub.status.idle":"2021-10-02T09:44:43.721731Z","shell.execute_reply.started":"2021-10-02T09:44:43.717274Z","shell.execute_reply":"2021-10-02T09:44:43.720755Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"## 여기 모델리에서는 트리계열의 모델들이 많았는데 현재 get_dummies로 열이 67개로 불어난 상황이다.\n## 특히 0,1로 이루어진 열들은 쓸데없는 가지를 치기 때문에 tree 모델이 처음에 안맞았다.\n\n## 또한, adaboost나 gradientboosting도 모두 예전꺼에다가 계속 수정을 하며 하기 때문에 많은 estimate로 overfit 된것 같다.\n## estimator를 줄이는것도 방법이 될 수 있다. ","metadata":{"execution":{"iopub.status.busy":"2021-10-02T09:44:43.724080Z","iopub.execute_input":"2021-10-02T09:44:43.724362Z","iopub.status.idle":"2021-10-02T09:44:43.732798Z","shell.execute_reply.started":"2021-10-02T09:44:43.724334Z","shell.execute_reply":"2021-10-02T09:44:43.732051Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"## 앙상블을 할 때 결과값들의 상관관계를 보는것은 흥미로웠다.\n## 후에 adaboost빼고 5개의 모델들로 hard voting해서 했다. \n## sklearn에서 찾아보면 soft도 있는데 soft는 값들의 평균. hard는 하나.\n\n## 또 다른 방법중에는 stacking과 blending 이 있다.\n## stacking은 쌓기. 모델들의 예측값들로만 또다른 데이터프레임 독립변수를 만들어서 종속변수를 예측.\n## blending은 섞기. 기존 데이터와 예측값들로 다시 훈련.\n## 참고 https://3months.tistory.com/486","metadata":{"execution":{"iopub.status.busy":"2021-10-02T09:44:43.734210Z","iopub.execute_input":"2021-10-02T09:44:43.734449Z","iopub.status.idle":"2021-10-02T09:44:43.743163Z","shell.execute_reply.started":"2021-10-02T09:44:43.734417Z","shell.execute_reply":"2021-10-02T09:44:43.742356Z"},"trusted":true},"execution_count":22,"outputs":[]}]}